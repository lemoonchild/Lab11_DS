{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Creación de 3 modelos"
      ],
      "metadata": {
        "id": "ZLcNfwEQjp7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Librerías a utilizar"
      ],
      "metadata": {
        "id": "FIId-DcwjkLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, RandomForestRegressor\n",
        "from sklearn.linear_model import LogisticRegression, Ridge\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    mean_squared_error,\n",
        "    mean_absolute_error,\n",
        "    r2_score\n",
        ")\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "DPeZRc0yj8ix"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carga de datos (preprocesados) a utilizar"
      ],
      "metadata": {
        "id": "EiM2NIEDkOwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n[1/6] Carga de datos...\")\n",
        "\n",
        "df_accidentes = pd.read_csv('./data_clean/data_accidentes_anio_depto.csv')\n",
        "df_dia_hora = pd.read_csv('./data_clean/data_accidentes_dia_hora.csv')\n",
        "df_tipos = pd.read_csv('./data_clean/data_accidentes_tipo_mes.csv')\n",
        "df_lesionados = pd.read_csv('./data_clean/data_lesionados_anio_depto.csv')\n",
        "df_fallecidos = pd.read_csv('./data_clean/data_fallecidos_anio_depto.csv')\n",
        "\n",
        "print(f\"Accidentes: {len(df_accidentes)} registros\")\n",
        "print(f\"Día/Hora: {len(df_dia_hora)} registros\")\n",
        "print(f\"Tipos: {len(df_tipos)} registros\")\n",
        "print(f\"Lesionados: {len(df_lesionados)} registros\")\n",
        "print(f\"Fallecidos: {len(df_fallecidos)} registros\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_q3REhnXkN__",
        "outputId": "62829b15-03e8-4530-d521-68f9e69761a4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[1/6] Carga de datos...\n",
            "Accidentes: 110 registros\n",
            "Día/Hora: 168 registros\n",
            "Tipos: 108 registros\n",
            "Lesionados: 110 registros\n",
            "Fallecidos: 110 registros\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo \\#1: Clasificación de Gravedad de Accidente"
      ],
      "metadata": {
        "id": "EgNpAkDQkdtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n[2/6] Preparando datos para Modelo 1...\")\n",
        "\n",
        "df_modelo1 = df_accidentes.merge(\n",
        "    df_lesionados,\n",
        "    on=['departamento', 'año'],\n",
        "    how='left'\n",
        ")\n",
        "df_modelo1 = df_modelo1.merge(\n",
        "    df_fallecidos,\n",
        "    on=['departamento', 'año'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "df_modelo1['tasa_mortalidad'] = df_modelo1['fallecidos'] / df_modelo1['accidentes']\n",
        "mediana_mortalidad = df_modelo1['tasa_mortalidad'].median()\n",
        "df_modelo1['alta_gravedad'] = (df_modelo1['tasa_mortalidad'] > mediana_mortalidad).astype(int)\n",
        "\n",
        "le_depto = LabelEncoder()\n",
        "df_modelo1['departamento_encoded'] = le_depto.fit_transform(df_modelo1['departamento'])\n",
        "df_modelo1['tasa_lesionados'] = df_modelo1['lesionados'] / df_modelo1['accidentes']\n",
        "\n",
        "X1 = df_modelo1[['año', 'departamento_encoded', 'accidentes', 'lesionados', 'tasa_lesionados']]\n",
        "y1 = df_modelo1['alta_gravedad']\n",
        "\n",
        "X1_train, X1_test, y1_train, y1_test = train_test_split(\n",
        "    X1, y1, test_size=0.25, random_state=42, stratify=y1\n",
        ")\n",
        "\n",
        "scaler1 = StandardScaler()\n",
        "X1_train_scaled = scaler1.fit_transform(X1_train)\n",
        "X1_test_scaled = scaler1.transform(X1_test)\n",
        "\n",
        "print(f\"Dataset: {len(X1)} registros\")\n",
        "print(f\"Train: {len(X1_train)} | Test: {len(X1_test)}\")\n",
        "print(f\"Distribución: {y1.value_counts().to_dict()}\")\n",
        "\n",
        "print(\"\\n   Entrenando Random Forest Classifier...\")\n",
        "modelo1_rf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    random_state=42,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "modelo1_rf.fit(X1_train_scaled, y1_train)\n",
        "y1_pred_rf = modelo1_rf.predict(X1_test_scaled)\n",
        "y1_proba_rf = modelo1_rf.predict_proba(X1_test_scaled)[:, 1]\n",
        "\n",
        "print(\"   Entrenando Gradient Boosting Classifier...\")\n",
        "modelo1_gb = GradientBoostingClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=5,\n",
        "    random_state=42\n",
        ")\n",
        "modelo1_gb.fit(X1_train_scaled, y1_train)\n",
        "y1_pred_gb = modelo1_gb.predict(X1_test_scaled)\n",
        "y1_proba_gb = modelo1_gb.predict_proba(X1_test_scaled)[:, 1]\n",
        "\n",
        "print(\"   Entrenando Logistic Regression...\")\n",
        "modelo1_lr = LogisticRegression(\n",
        "    random_state=42,\n",
        "    max_iter=1000,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "modelo1_lr.fit(X1_train_scaled, y1_train)\n",
        "y1_pred_lr = modelo1_lr.predict(X1_test_scaled)\n",
        "y1_proba_lr = modelo1_lr.predict_proba(X1_test_scaled)[:, 1]\n",
        "\n",
        "metricas1 = {\n",
        "    'Random Forest': {\n",
        "        'accuracy': accuracy_score(y1_test, y1_pred_rf),\n",
        "        'precision': precision_score(y1_test, y1_pred_rf),\n",
        "        'recall': recall_score(y1_test, y1_pred_rf),\n",
        "        'f1_score': f1_score(y1_test, y1_pred_rf),\n",
        "        'roc_auc': roc_auc_score(y1_test, y1_proba_rf),\n",
        "        'confusion_matrix': confusion_matrix(y1_test, y1_pred_rf).tolist()\n",
        "    },\n",
        "    'Gradient Boosting': {\n",
        "        'accuracy': accuracy_score(y1_test, y1_pred_gb),\n",
        "        'precision': precision_score(y1_test, y1_pred_gb),\n",
        "        'recall': recall_score(y1_test, y1_pred_gb),\n",
        "        'f1_score': f1_score(y1_test, y1_pred_gb),\n",
        "        'roc_auc': roc_auc_score(y1_test, y1_proba_gb),\n",
        "        'confusion_matrix': confusion_matrix(y1_test, y1_pred_gb).tolist()\n",
        "    },\n",
        "    'Logistic Regression': {\n",
        "        'accuracy': accuracy_score(y1_test, y1_pred_lr),\n",
        "        'precision': precision_score(y1_test, y1_pred_lr),\n",
        "        'recall': recall_score(y1_test, y1_pred_lr),\n",
        "        'f1_score': f1_score(y1_test, y1_pred_lr),\n",
        "        'roc_auc': roc_auc_score(y1_test, y1_proba_lr),\n",
        "        'confusion_matrix': confusion_matrix(y1_test, y1_pred_lr).tolist()\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"\\n   RESULTADOS MODELO 1:\")\n",
        "for modelo, metricas in metricas1.items():\n",
        "    print(f\"\\n   {modelo}:\")\n",
        "    print(f\"Accuracy:  {metricas['accuracy']:.4f}\")\n",
        "    print(f\"Precision: {metricas['precision']:.4f}\")\n",
        "    print(f\"Recall:    {metricas['recall']:.4f}\")\n",
        "    print(f\"F1-Score:  {metricas['f1_score']:.4f}\")\n",
        "    print(f\"ROC-AUC:   {metricas['roc_auc']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOsz3j0Ikscp",
        "outputId": "e6eb0c4e-6a7e-4570-9198-80eb1cdcc3ac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[2/6] Preparando datos para Modelo 1...\n",
            "Dataset: 110 registros\n",
            "Train: 82 | Test: 28\n",
            "Distribución: {0: 55, 1: 55}\n",
            "\n",
            "   Entrenando Random Forest Classifier...\n",
            "   Entrenando Gradient Boosting Classifier...\n",
            "   Entrenando Logistic Regression...\n",
            "\n",
            "   RESULTADOS MODELO 1:\n",
            "\n",
            "   Random Forest:\n",
            "Accuracy:  0.6786\n",
            "Precision: 0.6667\n",
            "Recall:    0.7143\n",
            "F1-Score:  0.6897\n",
            "ROC-AUC:   0.7398\n",
            "\n",
            "   Gradient Boosting:\n",
            "Accuracy:  0.5714\n",
            "Precision: 0.5556\n",
            "Recall:    0.7143\n",
            "F1-Score:  0.6250\n",
            "ROC-AUC:   0.7398\n",
            "\n",
            "   Logistic Regression:\n",
            "Accuracy:  0.6071\n",
            "Precision: 0.6154\n",
            "Recall:    0.5714\n",
            "F1-Score:  0.5926\n",
            "ROC-AUC:   0.6378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo \\#2: Predicción de Cantidad de Accidentes"
      ],
      "metadata": {
        "id": "qECKoU1vku65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n[3/6] Preparando datos para Modelo 2...\")\n",
        "\n",
        "df_modelo2 = df_accidentes.merge(\n",
        "    df_lesionados,\n",
        "    on=['departamento', 'año'],\n",
        "    how='left'\n",
        ")\n",
        "df_modelo2 = df_modelo2.merge(\n",
        "    df_fallecidos,\n",
        "    on=['departamento', 'año'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "le_depto2 = LabelEncoder()\n",
        "df_modelo2['departamento_encoded'] = le_depto2.fit_transform(df_modelo2['departamento'])\n",
        "\n",
        "df_modelo2['año_normalizado'] = (df_modelo2['año'] - df_modelo2['año'].min()) / \\\n",
        "                                 (df_modelo2['año'].max() - df_modelo2['año'].min())\n",
        "\n",
        "X2 = df_modelo2[['departamento_encoded', 'año_normalizado', 'lesionados', 'fallecidos']]\n",
        "y2 = df_modelo2['accidentes']\n",
        "\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(\n",
        "    X2, y2, test_size=0.25, random_state=42\n",
        ")\n",
        "\n",
        "scaler2 = StandardScaler()\n",
        "X2_train_scaled = scaler2.fit_transform(X2_train)\n",
        "X2_test_scaled = scaler2.transform(X2_test)\n",
        "\n",
        "print(f\"Dataset: {len(X2)} registros (usando TODOS los departamentos)\")\n",
        "print(f\"Train: {len(X2_train)} | Test: {len(X2_test)}\")\n",
        "\n",
        "print(\"\\n   Entrenando Random Forest Regressor...\")\n",
        "modelo2_rf = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=8,\n",
        "    min_samples_split=5,\n",
        "    random_state=42\n",
        ")\n",
        "modelo2_rf.fit(X2_train_scaled, y2_train)\n",
        "y2_pred_rf = modelo2_rf.predict(X2_test_scaled)\n",
        "\n",
        "print(\"   Entrenando Gradient Boosting Regressor...\")\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "modelo2_gb = GradientBoostingRegressor(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=5,\n",
        "    random_state=42\n",
        ")\n",
        "modelo2_gb.fit(X2_train_scaled, y2_train)\n",
        "y2_pred_gb = modelo2_gb.predict(X2_test_scaled)\n",
        "\n",
        "print(\"   Entrenando Ridge Regression...\")\n",
        "modelo2_ridge = Ridge(alpha=10.0, random_state=42)\n",
        "modelo2_ridge.fit(X2_train_scaled, y2_train)\n",
        "y2_pred_ridge = modelo2_ridge.predict(X2_test_scaled)\n",
        "\n",
        "metricas2 = {\n",
        "    'Random Forest': {\n",
        "        'mse': mean_squared_error(y2_test, y2_pred_rf),\n",
        "        'rmse': np.sqrt(mean_squared_error(y2_test, y2_pred_rf)),\n",
        "        'mae': mean_absolute_error(y2_test, y2_pred_rf),\n",
        "        'r2': r2_score(y2_test, y2_pred_rf)\n",
        "    },\n",
        "    'Gradient Boosting': {\n",
        "        'mse': mean_squared_error(y2_test, y2_pred_gb),\n",
        "        'rmse': np.sqrt(mean_squared_error(y2_test, y2_pred_gb)),\n",
        "        'mae': mean_absolute_error(y2_test, y2_pred_gb),\n",
        "        'r2': r2_score(y2_test, y2_pred_gb)\n",
        "    },\n",
        "    'Ridge Regression': {\n",
        "        'mse': mean_squared_error(y2_test, y2_pred_ridge),\n",
        "        'rmse': np.sqrt(mean_squared_error(y2_test, y2_pred_ridge)),\n",
        "        'mae': mean_absolute_error(y2_test, y2_pred_ridge),\n",
        "        'r2': r2_score(y2_test, y2_pred_ridge)\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"\\n   RESULTADOS Modelo 2:\")\n",
        "for modelo, metricas in metricas2.items():\n",
        "    print(f\"\\n   {modelo}:\")\n",
        "    print(f\"MSE:  {metricas['mse']:.2f}\")\n",
        "    print(f\"RMSE: {metricas['rmse']:.2f}\")\n",
        "    print(f\"MAE:  {metricas['mae']:.2f}\")\n",
        "    print(f\"R²:   {metricas['r2']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQO6Us3jlA9_",
        "outputId": "e78c10cb-7f95-4219-adb1-68ac62fb2028"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[3/6] Preparando datos para Modelo 2...\n",
            "Dataset: 110 registros (usando TODOS los departamentos)\n",
            "Train: 82 | Test: 28\n",
            "\n",
            "   Entrenando Random Forest Regressor...\n",
            "   Entrenando Gradient Boosting Regressor...\n",
            "   Entrenando Ridge Regression...\n",
            "\n",
            "   RESULTADOS Modelo 2:\n",
            "\n",
            "   Random Forest:\n",
            "MSE:  6542.28\n",
            "RMSE: 80.88\n",
            "MAE:  42.45\n",
            "R²:   0.9886\n",
            "\n",
            "   Gradient Boosting:\n",
            "MSE:  19996.15\n",
            "RMSE: 141.41\n",
            "MAE:  51.68\n",
            "R²:   0.9650\n",
            "\n",
            "   Ridge Regression:\n",
            "MSE:  15037.86\n",
            "RMSE: 122.63\n",
            "MAE:  71.00\n",
            "R²:   0.9737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo \\#3: Predicción de Riesgo por Día/Hora"
      ],
      "metadata": {
        "id": "-iW4poCIoxNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n[4/6] Preparando datos para Modelo 3...\")\n",
        "\n",
        "df_modelo3 = df_dia_hora.copy()\n",
        "\n",
        "dias_map = {\n",
        "    'lunes': 1, 'martes': 2, 'miercoles': 3, 'jueves': 4,\n",
        "    'viernes': 5, 'sabado': 6, 'domingo': 7\n",
        "}\n",
        "df_modelo3['dia_num'] = df_modelo3['dia_semana'].map(dias_map)\n",
        "\n",
        "q25 = df_modelo3['accidentes'].quantile(0.25)\n",
        "q75 = df_modelo3['accidentes'].quantile(0.75)\n",
        "\n",
        "def clasificar_riesgo(accidentes):\n",
        "    if accidentes >= q75:\n",
        "        return 2\n",
        "    elif accidentes >= q25:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "df_modelo3['nivel_riesgo'] = df_modelo3['accidentes'].apply(clasificar_riesgo)\n",
        "\n",
        "X3 = df_modelo3[['dia_num', 'hora_num']]\n",
        "y3 = df_modelo3['nivel_riesgo']\n",
        "\n",
        "X3_train, X3_test, y3_train, y3_test = train_test_split(\n",
        "    X3, y3, test_size=0.30, random_state=42, stratify=y3\n",
        ")\n",
        "\n",
        "scaler3 = StandardScaler()\n",
        "X3_train_scaled = scaler3.fit_transform(X3_train)\n",
        "X3_test_scaled = scaler3.transform(X3_test)\n",
        "\n",
        "print(f\"Dataset: {len(X3)} registros (168 combinaciones día/hora)\")\n",
        "print(f\"Clases: 0=Riesgo Bajo, 1=Riesgo Medio, 2=Riesgo Alto\")\n",
        "print(f\"Train: {len(X3_train)} | Test: {len(X3_test)}\")\n",
        "print(f\"Distribución: {pd.Series(y3).value_counts().to_dict()}\")\n",
        "\n",
        "print(\"\\n   Entrenando Random Forest Classifier (3 niveles de riesgo)...\")\n",
        "modelo3_rf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=8,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=3,\n",
        "    random_state=42,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "modelo3_rf.fit(X3_train_scaled, y3_train)\n",
        "y3_pred_rf = modelo3_rf.predict(X3_test_scaled)\n",
        "\n",
        "# Entrenar Gradient Boosting\n",
        "print(\"   Entrenando Gradient Boosting Classifier (3 niveles de riesgo)...\")\n",
        "modelo3_gb = GradientBoostingClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=4,\n",
        "    random_state=42\n",
        ")\n",
        "modelo3_gb.fit(X3_train_scaled, y3_train)\n",
        "y3_pred_gb = modelo3_gb.predict(X3_test_scaled)\n",
        "\n",
        "# Entrenar Decision Tree (más interpretable)\n",
        "print(\"   Entrenando Decision Tree Classifier (3 niveles de riesgo)...\")\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "modelo3_dt = DecisionTreeClassifier(\n",
        "    max_depth=6,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=3,\n",
        "    random_state=42,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "modelo3_dt.fit(X3_train_scaled, y3_train)\n",
        "y3_pred_dt = modelo3_dt.predict(X3_test_scaled)\n",
        "\n",
        "# Métricas Modelo 3\n",
        "metricas3 = {\n",
        "    'Random Forest': {\n",
        "        'accuracy': accuracy_score(y3_test, y3_pred_rf),\n",
        "        'precision': precision_score(y3_test, y3_pred_rf, average='weighted', zero_division=0),\n",
        "        'recall': recall_score(y3_test, y3_pred_rf, average='weighted'),\n",
        "        'f1_score': f1_score(y3_test, y3_pred_rf, average='weighted'),\n",
        "        'confusion_matrix': confusion_matrix(y3_test, y3_pred_rf).tolist()\n",
        "    },\n",
        "    'Gradient Boosting': {\n",
        "        'accuracy': accuracy_score(y3_test, y3_pred_gb),\n",
        "        'precision': precision_score(y3_test, y3_pred_gb, average='weighted', zero_division=0),\n",
        "        'recall': recall_score(y3_test, y3_pred_gb, average='weighted'),\n",
        "        'f1_score': f1_score(y3_test, y3_pred_gb, average='weighted'),\n",
        "        'confusion_matrix': confusion_matrix(y3_test, y3_pred_gb).tolist()\n",
        "    },\n",
        "    'Decision Tree': {\n",
        "        'accuracy': accuracy_score(y3_test, y3_pred_dt),\n",
        "        'precision': precision_score(y3_test, y3_pred_dt, average='weighted', zero_division=0),\n",
        "        'recall': recall_score(y3_test, y3_pred_dt, average='weighted'),\n",
        "        'f1_score': f1_score(y3_test, y3_pred_dt, average='weighted'),\n",
        "        'confusion_matrix': confusion_matrix(y3_test, y3_pred_dt).tolist()\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"\\n   RESULTADOS Modelo 3:\")\n",
        "for modelo, metricas in metricas3.items():\n",
        "    print(f\"\\n   {modelo}:\")\n",
        "    print(f\"      Accuracy:  {metricas['accuracy']:.4f}\")\n",
        "    print(f\"      Precision: {metricas['precision']:.4f}\")\n",
        "    print(f\"      Recall:    {metricas['recall']:.4f}\")\n",
        "    print(f\"      F1-Score:  {metricas['f1_score']:.4f}\")\n",
        "\n",
        "from collections import Counter\n",
        "print(\"\\n   Distribución de clases:\")\n",
        "print(f\"      Real:      {Counter(y3_test)}\")\n",
        "print(f\"      Predicho:  {Counter(y3_pred_rf)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyXAcJF6q7tC",
        "outputId": "894df044-e23e-42bc-92a5-b8a721d073ad"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[4/6] Preparando datos para Modelo 3...\n",
            "Dataset: 168 registros (168 combinaciones día/hora)\n",
            "Clases: 0=Riesgo Bajo, 1=Riesgo Medio, 2=Riesgo Alto\n",
            "Train: 117 | Test: 51\n",
            "Distribución: {1: 87, 2: 43, 0: 38}\n",
            "\n",
            "   Entrenando Random Forest Classifier (3 niveles de riesgo)...\n",
            "   Entrenando Gradient Boosting Classifier (3 niveles de riesgo)...\n",
            "   Entrenando Decision Tree Classifier (3 niveles de riesgo)...\n",
            "\n",
            "   RESULTADOS Modelo 3:\n",
            "\n",
            "   Random Forest:\n",
            "      Accuracy:  0.6667\n",
            "      Precision: 0.6833\n",
            "      Recall:    0.6667\n",
            "      F1-Score:  0.6705\n",
            "\n",
            "   Gradient Boosting:\n",
            "      Accuracy:  0.6078\n",
            "      Precision: 0.6164\n",
            "      Recall:    0.6078\n",
            "      F1-Score:  0.6055\n",
            "\n",
            "   Decision Tree:\n",
            "      Accuracy:  0.5686\n",
            "      Precision: 0.5772\n",
            "      Recall:    0.5686\n",
            "      F1-Score:  0.5686\n",
            "\n",
            "   Distribución de clases:\n",
            "      Real:      Counter({1: 26, 2: 13, 0: 12})\n",
            "      Predicho:  Counter({np.int64(1): 22, np.int64(0): 15, np.int64(2): 14})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Guardado de modelos entrenados"
      ],
      "metadata": {
        "id": "adIZJABnrI0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n[5/6] Guardando modelos entrenados...\")\n",
        "\n",
        "# Modelo 1: Clasificación de Gravedad\n",
        "with open('./models/modelo1_gravedad.pkl', 'wb') as f:\n",
        "    pickle.dump({\n",
        "        'random_forest': modelo1_rf,\n",
        "        'gradient_boosting': modelo1_gb,\n",
        "        'logistic_regression': modelo1_lr,\n",
        "        'scaler': scaler1,\n",
        "        'label_encoder_depto': le_depto,\n",
        "        'feature_names': list(X1.columns),\n",
        "        'metricas': metricas1\n",
        "    }, f)\n",
        "print(\"   Modelo 1 guardado: ./models/modelo1_gravedad.pkl\")\n",
        "\n",
        "# Modelo 2: Regresión de Cantidad (CORREGIDO)\n",
        "with open('./models/modelo2_cantidad.pkl', 'wb') as f:\n",
        "    pickle.dump({\n",
        "        'random_forest': modelo2_rf,\n",
        "        'gradient_boosting': modelo2_gb,\n",
        "        'ridge': modelo2_ridge,\n",
        "        'scaler': scaler2,\n",
        "        'label_encoder_depto': le_depto2,\n",
        "        'feature_names': list(X2.columns),\n",
        "        'metricas': metricas2\n",
        "    }, f)\n",
        "print(\"   Modelo 2 guardado: ./models/modelo2_cantidad.pkl\")\n",
        "\n",
        "# Modelo 3: Clasificación de Nivel de Riesgo (NUEVO ENFOQUE)\n",
        "with open('./models/modelo3_tipo.pkl', 'wb') as f:\n",
        "    pickle.dump({\n",
        "        'random_forest': modelo3_rf,\n",
        "        'gradient_boosting': modelo3_gb,\n",
        "        'decision_tree': modelo3_dt,\n",
        "        'scaler': scaler3,\n",
        "        'dias_map': dias_map,\n",
        "        'niveles_riesgo': ['Bajo', 'Medio', 'Alto'],\n",
        "        'feature_names': list(X3.columns),\n",
        "        'metricas': metricas3\n",
        "    }, f)\n",
        "print(\"   Modelo 3 guardado: ./models/modelo3_tipo.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YI3K7nAMq_vY",
        "outputId": "c6643b39-0135-42b5-b9c2-09a313895378"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[5/6] Guardando modelos entrenados...\n",
            "   Modelo 1 guardado: ./models/modelo1_gravedad.pkl\n",
            "   Modelo 2 guardado: ./models/modelo2_cantidad.pkl\n",
            "   Modelo 3 guardado: ./models/modelo3_tipo.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resumen de metricas por modelo"
      ],
      "metadata": {
        "id": "aZl_YUzvrQ2f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fSCd4GOgDKt",
        "outputId": "2c5baea0-6104-4706-9fce-186b3c6f28a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[6/6] Generando reporte de entrenamiento...\n",
            "Resumen guardado: ./models/resumen_modelos.json\n",
            "\n",
            "MEJOR MODELO POR CATEGORÍA:\n",
            "\n",
            "   Modelo 1 (Gravedad): Random Forest\n",
            "      F1-Score: 0.6897\n",
            "\n",
            "   Modelo 2 (Cantidad): Random Forest\n",
            "      RMSE: 80.88\n",
            "      R²:   0.9886\n",
            "\n",
            "   Modelo 3 (Tipo): Random Forest\n",
            "      F1-Score: 0.6705\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n[6/6] Generando reporte de entrenamiento...\")\n",
        "\n",
        "resumen = {\n",
        "    'fecha_entrenamiento': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "    'version': 'CORREGIDA',\n",
        "    'modelo1_gravedad': {\n",
        "        'descripcion': 'Clasificación binaria: Predice si un accidente tendrá alta gravedad (alta tasa de mortalidad)',\n",
        "        'algoritmos': ['Random Forest', 'Gradient Boosting', 'Logistic Regression'],\n",
        "        'features': list(X1.columns),\n",
        "        'n_samples': len(X1),\n",
        "        'metricas': metricas1\n",
        "    },\n",
        "    'modelo2_cantidad': {\n",
        "        'descripcion': 'Regresión: Predice la cantidad de accidentes por departamento',\n",
        "        'cambios': 'Usa 110 registros (departamentos x años) en vez de 4 agregados',\n",
        "        'algoritmos': ['Random Forest', 'Gradient Boosting', 'Ridge Regression'],\n",
        "        'features': list(X2.columns),\n",
        "        'n_samples': len(X2),\n",
        "        'metricas': metricas2\n",
        "    },\n",
        "    'modelo3_tipo': {\n",
        "        'descripcion': 'Clasificación de nivel de riesgo: Predice si un momento del día/semana tiene riesgo Bajo/Medio/Alto',\n",
        "        'cambios': 'Cambio completo de enfoque: usa 168 registros (día/hora) en vez de 60 (tipos). Evita overfitting.',\n",
        "        'algoritmos': ['Random Forest', 'Gradient Boosting', 'Decision Tree'],\n",
        "        'features': list(X3.columns),\n",
        "        'n_samples': len(X3),\n",
        "        'clases': ['Bajo', 'Medio', 'Alto'],\n",
        "        'metricas': metricas3\n",
        "    }\n",
        "}\n",
        "\n",
        "with open('./models/resumen_modelos.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(resumen, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"Resumen guardado: ./models/resumen_modelos.json\")\n",
        "\n",
        "print(\"\\nMEJOR MODELO POR CATEGORÍA:\")\n",
        "\n",
        "# Mejor modelo 1\n",
        "mejor_m1 = max(metricas1.items(), key=lambda x: x[1]['f1_score'])\n",
        "print(f\"\\n   Modelo 1 (Gravedad): {mejor_m1[0]}\")\n",
        "print(f\"      F1-Score: {mejor_m1[1]['f1_score']:.4f}\")\n",
        "\n",
        "# Mejor modelo 2\n",
        "mejor_m2 = min(metricas2.items(), key=lambda x: x[1]['rmse'])\n",
        "print(f\"\\n   Modelo 2 (Cantidad): {mejor_m2[0]}\")\n",
        "print(f\"      RMSE: {mejor_m2[1]['rmse']:.2f}\")\n",
        "print(f\"      R²:   {mejor_m2[1]['r2']:.4f}\")\n",
        "\n",
        "# Mejor modelo 3\n",
        "mejor_m3 = max(metricas3.items(), key=lambda x: x[1]['f1_score'])\n",
        "print(f\"\\n   Modelo 3 (Tipo): {mejor_m3[0]}\")\n",
        "print(f\"      F1-Score: {mejor_m3[1]['f1_score']:.4f}\")"
      ]
    }
  ]
}